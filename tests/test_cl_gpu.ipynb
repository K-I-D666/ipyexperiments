{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CellLogger subsystem\n",
    "\n",
    "This test tests the CellLogger subsystem, accessible via `exp.cl` once one of the `IPyExperiments` subclasses has been initiated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test specifics\n",
    "\n",
    "Since we need to validate the the output, we have to capture it first. The way jupyter is setup, is that in once cell you set up a capture with `%%capture` magick and then in the next cell you can analyze it. That's why each test group has two cells, the first one doing the action to be tested and the following one doing the validatations.\n",
    "\n",
    "Moreover, the output of this test becomes confusing because the capture mechanism somehow messes things up which leads to re-running the `post_run_cell` callback of the CellLogger subsystem again - as a result you get a bogus output with 0's regardless of the code being run. It doesn't interfere with the testing, but it does interfere with things like `.data` which gets reset because of that, showing invalid information - therefore we can only test `.data` w/o capturing the cell's output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyexperiments import *\n",
    "from utils.text import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipyexperiments.cell_logger.CellLogger object at 0x7f961667bc50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.005\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "#if 'exp' in locals(): exp.cl.stop() # helps debug\n",
    "exp1 = IPyExperimentsPytorch(exp_enable=False)\n",
    "exp1.cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.127\n",
      "･ CPU:          0          0      1,460 MB |\n",
      "･ GPU:          0          0      5,620 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "gpu1 = consume_gpu_ram_256mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.111\n",
      "| ･ CPU:        128          0      1,460 MB |\n",
      "| ･ GPU:        256          0      5,620 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.004\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:       -256          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_strings(output)\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=0, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=0, abs_tol=0)\n",
    "\n",
    "# cleanup\n",
    "del cpu1, gpu1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume/release leading to positive peak numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.178\n",
      "･ CPU:          0          0      1,460 MB |\n",
      "･ GPU:          0        256      5,620 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test peak measurement\n",
    "# here we consume 256MB of RAM and release 128MB \n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_peak_memory_usage'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.165\n",
      "| ･ CPU:        128        128      1,460 MB |\n",
      "| ･ GPU:        256        256      5,620 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.004\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:       -256          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_peak_memory_usage\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "\n",
    "check_report_cpu(output, consumed_expected=128, peaked_expected=128, abs_tol=2)\n",
    "check_report_gpu(output, consumed_expected=256, peaked_expected=256, abs_tol=2)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .data accessor validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.207\n",
      "･ CPU:        128        128      1,460 MB |\n",
      "･ GPU:        256        256      5,620 MB |\n"
     ]
    }
   ],
   "source": [
    "# no capture! breaks .data since it re-runs the post_run_cell, again, resetting .data\n",
    "# here we consume 256MB of RAM and release 128MB - so that we can test peak measurement\n",
    "# testing: Consumed 128, Peaked 128\n",
    "cpu1 = consume_cpu_ram_128mb()\n",
    "cpu2 = consume_cpu_ram_128mb()\n",
    "del cpu1\n",
    "\n",
    "# here we consume 512MB of RAM and release 256MB - so that we can test peak measurement\n",
    "# testing: Consumed 256, Peaked 256\n",
    "gpu1 = consume_gpu_ram_256mb()\n",
    "gpu2 = consume_gpu_ram_256mb()\n",
    "## Consume/Release Positive Peak\n",
    "del gpu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_data_accessor'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134221685\n",
      "134235314\n",
      "268435456\n",
      "268435456\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.004\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:       -256          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_data_accessor\"\"\"\n",
    "cpu_mem   = exp1.cl.data.cpu\n",
    "gpu_mem   = exp1.cl.data.gpu\n",
    "time_data = exp1.cl.data.time\n",
    "check_match(consumed_reported=b2mb(cpu_mem.used_delta), peaked_reported=b2mb(cpu_mem.peaked_delta), \n",
    "            consumed_expected=128,                      peaked_expected=128,  abs_tol=1)\n",
    "check_match(consumed_reported=b2mb(gpu_mem.used_delta), peaked_reported=b2mb(gpu_mem.peaked_delta), \n",
    "            consumed_expected=256,                      peaked_expected=256, abs_tol=1)\n",
    "\n",
    "# cleanup\n",
    "del cpu2, gpu2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_stop'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.137\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_stop\"\"\"\n",
    "exp1.cl.stop()\n",
    "#check that no output appears after this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "cpu1 = consume_cpu_ram_128mb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_report'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No captured output\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_report\"\"\"\n",
    "output = str(output)\n",
    "print_output(output)\n",
    "assert output == \"\", \"there should be no output as logger has been stopped\"\n",
    "\n",
    "# cleanup\n",
    "del cpu1\n",
    "del exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals_unset(['exp10'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.036\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned on, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)\n",
    "exp10 = IPyExperimentsPytorch(exp_enable=True, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:    Used    Free   Total       Util\n",
      "| CPU:   1,332   7,709  31,588 MB   4.22% \n",
      "| GPU:   5,364   6,848  12,212 MB  43.92% \n",
      "| \n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "| \n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:    Used    Free   Total       Util\n",
      "| CPU:   1,332   7,708  31,588 MB   4.22% \n",
      "| GPU:   5,364   6,848  12,212 MB  43.92% \n",
      "| \n",
      "| \n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.026\n",
      "| ･ CPU:          0          0      1,332 MB |\n",
      "| ･ GPU:          0          0      5,364 MB |\n",
      "| \n",
      "| IPyExperimentsPytorch: Finishing\n",
      "| \n",
      "| *** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "| \n",
      "| *** Experiment memory:\n",
      "| RAM: Consumed       Reclaimed\n",
      "| CPU:        0        0 MB (100.00%)\n",
      "| GPU:        0        0 MB (100.00%)\n",
      "| \n",
      "| *** Current state:\n",
      "| RAM:    Used    Free   Total       Util\n",
      "| CPU:   1,332   7,708  31,588 MB   4.22% \n",
      "| GPU:   5,364   6,848  12,212 MB  43.92% \n",
      "| \n",
      "| \n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.024\n",
      "| ･ CPU:          0          0      1,332 MB |\n",
      "| ･ GPU:          0          0      5,364 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.002\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\"\n",
    "\n",
    "match = re.findall(r'started', output)\n",
    "assert len(match) == 2, f\"should have started twice, got {len(match)}\"\n",
    "\n",
    "match = re.findall(r'Finishing', output)\n",
    "assert len(match) == 1, f\"should have finished once, got {len(match)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.043\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n",
      "\n",
      "IPyExperimentsPytorch: Finishing\n",
      "\n",
      "*** Experiment finished in 00:00:00 (elapsed wallclock time)\n",
      "\n",
      "*** Newly defined local variables:\n",
      "Deleted: match\n",
      "\n",
      "*** Experiment memory:\n",
      "RAM: Consumed       Reclaimed\n",
      "CPU:        0        0 MB (  0.00%)\n",
      "GPU:        0        0 MB (100.00%)\n",
      "\n",
      "*** Current state:\n",
      "RAM:    Used    Free   Total       Util\n",
      "CPU:   1,332   7,704  31,588 MB   4.22% \n",
      "GPU:   5,364   6,848  12,212 MB  43.92% \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit destroy #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.022\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "%%capture output\n",
    "# test destroy which happens when obj is redefined \n",
    "# this one tests with the exp-system turned off, cl-system turned on\n",
    "# this is a pretty normal situation, considering that someone will be reloading the same cell\n",
    "# do not change this test!\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)\n",
    "exp11 = IPyExperimentsPytorch(exp_enable=False, cl_enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured output:\n",
      "============================================================\n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "| \n",
      "| \n",
      "| *** Experiment started with the Pytorch backend\n",
      "| Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "| \n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.025\n",
      "| ･ CPU:          0          0      1,332 MB |\n",
      "| ･ GPU:          0          0      5,364 MB |\n",
      "| ･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.011\n",
      "| ･ CPU:          0          0      1,332 MB |\n",
      "| ･ GPU:          0          0      5,364 MB |\n",
      "| \n",
      "============================================================\n",
      "\n",
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.000\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "output = str(output)\n",
    "print_output(output)\n",
    "assert \"Error\" not in output, \"shouldn't fail on auto-destruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "･ RAM:  △Consumed    △Peaked    Used Total | Exec time 0:00:00.042\n",
      "･ CPU:          0          0      1,332 MB |\n",
      "･ GPU:          0          0      5,364 MB |\n"
     ]
    }
   ],
   "source": [
    "# cleanup\n",
    "del exp11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_random_reset_a'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "\n",
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_random_reset_a\"\"\"\n",
    "# a. baseline - rand is different by default\n",
    "exp12 = IPyExperimentsPytorch(exp_enable=False, cl_set_seed=0, cl_compact=True)\n",
    "rnd1 = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "rnd2 = np.random.random()\n",
    "assert rnd1 != rnd2, f\"values should be different rnd1={rnd1} rnd2={rnd2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.025 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "del exp12 # cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_random_reset_b'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "\n",
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_random_reset_b\"\"\"\n",
    "# b. now automatically reset the seed on each cell run and except the same rand values\n",
    "exp13 = IPyExperimentsPytorch(exp_enable=False, cl_set_seed=42, cl_compact=True)\n",
    "rnd1 = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.001 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "rnd2 = np.random.random()\n",
    "assert rnd1 == rnd2, f\"values should be the same rnd1={rnd1} rnd2={rnd2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.032 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "del exp13 # cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test_random_reset_c'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Experiment started with the Pytorch backend\n",
      "Device: ID 0, GeForce GTX TITAN X (12212 RAM)\n",
      "\n",
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.000 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test_random_reset_c\"\"\"\n",
    "# c. now back to non-resetting, should be different rand values again\n",
    "exp14 = IPyExperimentsPytorch(exp_enable=False, cl_set_seed=0, cl_compact=True)\n",
    "rnd1 = np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.001 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "rnd2 = np.random.random()\n",
    "assert rnd1 != rnd2, f\"values should be again different rnd1={rnd1} rnd2={rnd2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 0/0/1332 MB | GPU: 0/0/5364 MB | Time 0:00:00.031 | (Consumed/Peaked/Used Total)\n"
     ]
    }
   ],
   "source": [
    "del exp14 # cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.save_notebook()\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript # prevent committing an unsaved notebook\n",
    "IPython.notebook.save_notebook()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "323px",
    "left": "956px",
    "right": "20px",
    "top": "152px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
